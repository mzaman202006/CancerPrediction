# -*- coding: utf-8 -*-
"""Predicting Breast Cancer_ANN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/github/mzaman202006/CancerPrediction/blob/main/Predicting_Breast_Cancer_ANN.ipynb
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix, classification_report, precision_score,recall_score,f1_score


import tensorflow as tf
from tensorflow.keras import layers, callbacks
from tensorflow.keras import Model, Sequential
from keras.models import Sequential
from keras.layers import Dense, Dropout

import sklearn
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler, LabelEncoder


df = pd.read_csv('data.csv')
del df['Unnamed: 32']

cols = ['radius_worst', 
        'texture_worst', 
        'perimeter_worst', 
        'area_worst', 
        'smoothness_worst', 
        'compactness_worst', 
        'concavity_worst',
        'concave points_worst', 
        'symmetry_worst', 
        'fractal_dimension_worst']
df = df.drop(cols, axis=1)


cols = ['perimeter_mean',
        'perimeter_se', 
        'area_mean', 
        'area_se']
df = df.drop(cols, axis=1)
df.columns

X = df.iloc[:, 2:].values
y = df.iloc[:, 1].values
from sklearn.preprocessing import LabelEncoder
labelencoder_X_1 = LabelEncoder()
y = labelencoder_X_1.fit_transform(y)


from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state = 0)

#Feature Scaling
from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
X_train = sc.fit_transform(X_train)
X_test = sc.transform(X_test)

import keras
from keras.models import Sequential
from keras.layers import Dense, Dropout
md = Sequential()

md.add(Dense(units=8, kernel_initializer='normal', activation='relu', input_dim=16))

md.add(Dropout(rate=0.1))


md.add(Dense(units=8, kernel_initializer='normal', activation='relu'))

md.add(Dropout(rate=0.1))
md.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

md.add(Dense(units=1, kernel_initializer='normal', activation='sigmoid'))




#md.fit(X_train, y_train, batch_size=100, epochs=250)

"""#History VIEW

"""

import time
start = time.perf_counter()

early_stopping = callbacks.EarlyStopping(monitor ="val_loss", 
                                          patience=30)

history = md.fit(X_train, y_train,
                    epochs = 500, 
                    validation_data = (X_test, y_test), 
                    shuffle = True)

elapsed = time.perf_counter() - start
print('Elapsed %.3f seconds.' % elapsed)

#Presentation of accuracy and loss
acc = history.history['accuracy']
val_acc = history.history['val_accuracy']

loss = history.history['loss']
val_loss = history.history['val_loss']

epochs_range = range(1, len(val_acc)+1)
plt.figure(figsize=(12, 4))

plt.subplot(1, 2, 1)
plt.plot(epochs_range, acc, label='Training Accuracy')
plt.plot(epochs_range, val_acc, label='Validation Accuracy')
plt.legend(loc='lower right')
plt.xlim(1, len(val_acc)+1)
plt.title('Training and Validation Accuracy')

plt.subplot(1, 2, 2)
plt.plot(epochs_range, loss, label='Training Loss')
plt.plot(epochs_range, val_loss, label='Validation Loss')
plt.legend(loc='upper right')
plt.xlim(1, len(val_acc)+1)
plt.title('Training and Validation Loss')
plt.show()

y_pred = md.predict(X_test)
y_pred = (y_pred > 0.5)

from sklearn.metrics import confusion_matrix
cm = confusion_matrix(y_test, y_pred)
print("accuracy  {}%".format(((cm[0][0] + cm[1][1])/57)*100))

precision = precision_score(y_test, y_pred, average='binary')
recall = recall_score(y_test, y_pred, average='binary')
score = f1_score(y_test, y_pred, average='binary')
print('Precision : ',precision *100 ,' %')
print('Recall : ' ,recall*100 ,' %') 
print('F1_score : ', score*100 ,' %')

sns.heatmap(cm,annot=True)
plt.savefig('h.png')